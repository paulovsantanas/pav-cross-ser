{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "import glob\n",
    "import os\n",
    "import torchaudio\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import ast\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from torch.optim import Adam\n",
    "\n",
    "from accelerate import Accelerator\n",
    "from huggingface_hub import create_repo\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "\n",
    "from accelerate.utils import ProjectConfiguration\n",
    "\n",
    "from diffusers.optimization import get_cosine_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find pav-ser.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpaulovsantanas\u001b[0m (\u001b[33mpaulovsantanasteam\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/paulosantana/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import wandb\n",
    "\n",
    "load_dotenv(dotenv_path='variables.env')\n",
    "wandb.login(key=os.environ[\"WANDB_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://zenodo.org/record/5427549/files/emoUERJ.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# !unzip emoUERJ.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR='emoUERJ'\n",
    "DEVICE='cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmoUERJFeatureDataset(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Position 1: actor's gender ('m' for man or 'w' for woman)\n",
    "    Positions 2 and 3: actor's id (from 01 to 04)\n",
    "    Position 4: emotion (h: happiness, a: anger, s: sadness, n: neutral)\n",
    "    Positions 5 and 6: recording identification\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        labels=[\"h\", \"a\", \"s\", \"n\"],\n",
    "        actor_ids=[1, 2, 3, 4],\n",
    "        data_path=DATASET_DIR,\n",
    "        device=DEVICE,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.DEVICE = device\n",
    "        self.all_file_paths = glob.glob(\n",
    "            os.path.join(data_path, \"**\", \"*.pt\"), recursive=True\n",
    "        )\n",
    "        # Filtra o dataset por atores (útil para criar conjuntos de teste e validação)\n",
    "        self.actor_ids = actor_ids\n",
    "        self.file_paths = list(\n",
    "            filter(\n",
    "                lambda fp: int(os.path.basename(fp)[2]) in actor_ids,\n",
    "                self.all_file_paths,\n",
    "            )\n",
    "        )\n",
    "        self.labels = labels\n",
    "\n",
    "    @property\n",
    "    def num_labels(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_label_id(self, label):\n",
    "        return self.labels.index(label)\n",
    "\n",
    "    def _get_label_by_fp(self, fp):\n",
    "        name = os.path.basename(fp)\n",
    "        label = name[3]\n",
    "        return label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        fp = self.file_paths[index]\n",
    "        label_id = self.get_label_id(self._get_label_by_fp(fp))\n",
    "        feature = torch.load(fp)\n",
    "        return feature, int(label_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmoUERJDataset(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Position 1: actor's gender ('m' for man or 'w' for woman)\n",
    "    Positions 2 and 3: actor's id (from 01 to 04)\n",
    "    Position 4: emotion (h: happiness, a: anger, s: sadness, n: neutral)\n",
    "    Positions 5 and 6: recording identification\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        feature_extractor,\n",
    "        labels=[\"h\", \"a\", \"s\", \"n\"],\n",
    "        actor_ids=[1, 2, 3, 4],\n",
    "        data_path=DATASET_DIR,\n",
    "        device=DEVICE,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.DEVICE = device\n",
    "        self.all_file_paths = glob.glob(\n",
    "            os.path.join(data_path, \"**\", \"*.wav\"), recursive=True\n",
    "        )\n",
    "        # Filtra o dataset por atores (útil para criar conjuntos de teste e validação)\n",
    "        self.actor_ids = actor_ids\n",
    "        self.file_paths = list(\n",
    "            filter(\n",
    "                lambda fp: int(os.path.basename(fp)[2]) in actor_ids,\n",
    "                self.all_file_paths,\n",
    "            )\n",
    "        )\n",
    "        self.labels = labels\n",
    "        self.feature_extractor = feature_extractor\n",
    "\n",
    "    @property\n",
    "    def num_labels(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_label_id(self, label):\n",
    "        return self.labels.index(label)\n",
    "\n",
    "    def _get_label_by_fp(self, fp):\n",
    "        name = os.path.basename(fp)\n",
    "        label = name[3]\n",
    "        return label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        fp = self.file_paths[index]\n",
    "        label_id = self.get_label_id(self._get_label_by_fp(fp))\n",
    "        feature = self.feature_extractor(fp)\n",
    "        return torch.Tensor(feature).float(), int(label_id), os.path.splitext(os.path.basename(fp))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bundle_wavlm = torchaudio.pipelines.WAVLM_LARGE\n",
    "wavlm = bundle_wavlm.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bundle_hubert = torchaudio.pipelines.HUBERT_XLARGE\n",
    "hubert = bundle_hubert.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import librosa\n",
    "from torchaudio.transforms import (\n",
    "    Resample,\n",
    "    Spectrogram,\n",
    "    MelSpectrogram,\n",
    "    TimeStretch,\n",
    "    FrequencyMasking,\n",
    "    TimeMasking,\n",
    "    MelScale,\n",
    ")\n",
    "from torchaudio.functional import detect_pitch_frequency\n",
    "\n",
    "\n",
    "class Preprocessing(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self, duration: float = 7, input_freq: int = 44100, resample_freq: int = 16000\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_samples = int(duration * resample_freq)\n",
    "        self.resample = Resample(orig_freq=input_freq, new_freq=resample_freq)\n",
    "\n",
    "    def _to_mono(self, waveform):\n",
    "        if waveform.shape[0] > 1:\n",
    "            waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
    "        return waveform\n",
    "\n",
    "    def _cut_if_necessary(self, waveform: torch.Tensor) -> torch.Tensor:\n",
    "        if waveform.shape[1] > self.num_samples:\n",
    "            waveform = waveform[:, : self.num_samples]\n",
    "        return waveform\n",
    "\n",
    "    def _right_pad_if_necessary(self, waveform: torch.Tensor) -> torch.Tensor:\n",
    "        num_samples = waveform.shape[1]\n",
    "        if num_samples < self.num_samples:\n",
    "            num_missing_samples = self.num_samples - num_samples\n",
    "            last_dim_padding = (0, num_missing_samples)\n",
    "            waveform = torch.nn.functional.pad(waveform, last_dim_padding)\n",
    "        return waveform\n",
    "\n",
    "    def forward(self, waveform: torch.Tensor) -> torch.Tensor:\n",
    "        preprocessed_waveform = self.resample(self._to_mono(waveform))\n",
    "        preprocessed_waveform = self._cut_if_necessary(preprocessed_waveform)\n",
    "        preprocessed_waveform = self._right_pad_if_necessary(preprocessed_waveform)\n",
    "        return preprocessed_waveform\n",
    "\n",
    "\n",
    "class MelFeatureExtractor(torch.nn.Module):\n",
    "    def __init__(self, n_fft: int = 1024, n_mels: int = 80, sample_rate: int = 16000):\n",
    "        super().__init__()\n",
    "\n",
    "        self.spec = Spectrogram(n_fft=n_fft, power=2)\n",
    "\n",
    "        self.spec_aug = torch.nn.Sequential(\n",
    "            FrequencyMasking(freq_mask_param=80),\n",
    "            TimeMasking(time_mask_param=80),\n",
    "        )\n",
    "\n",
    "        self.mel_scale = MelScale(\n",
    "            n_mels=n_mels, sample_rate=sample_rate, n_stft=n_fft // 2 + 1\n",
    "        )\n",
    "\n",
    "    def forward(self, waveform: torch.Tensor) -> torch.Tensor:\n",
    "        spec = self.spec(waveform)\n",
    "        spec = self.spec_aug(spec)\n",
    "        mel = self.mel_scale(spec)\n",
    "\n",
    "        return mel\n",
    "\n",
    "\n",
    "class ModelFeatureExtractor(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, waveform: torch.Tensor) -> torch.Tensor:\n",
    "        features, _ = self.model.extract_features(waveform)\n",
    "\n",
    "        return features[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileToFeature(torch.nn.Module):\n",
    "    def __init__(self, feature_extractor):\n",
    "        super().__init__()\n",
    "        self.preprocess = Preprocessing()\n",
    "        self.extract_feature = feature_extractor\n",
    "\n",
    "    def forward(self, fp: str) -> torch.Tensor:\n",
    "        x, sr = torchaudio.load(fp)\n",
    "        x = self.preprocess(x)\n",
    "        return self.extract_feature(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Melspectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train files: 185\n",
      "Total validation files: 87\n",
      "Total test files: 105\n"
     ]
    }
   ],
   "source": [
    "melspec_train_dataset = EmoUERJDataset(\n",
    "    FileToFeature(MelFeatureExtractor()),\n",
    "    actor_ids=[1, 2]\n",
    ")\n",
    "print(f\"Total train files: {len(melspec_train_dataset)}\")\n",
    "melspec_valid_dataset = EmoUERJDataset(\n",
    "    FileToFeature(MelFeatureExtractor()),\n",
    "    actor_ids=[3]\n",
    ")\n",
    "print(f\"Total validation files: {len(melspec_valid_dataset)}\")\n",
    "mel_test_dataset = EmoUERJDataset(\n",
    "    FileToFeature(MelFeatureExtractor()),\n",
    "    actor_ids=[4]\n",
    ")\n",
    "print(f\"Total test files: {len(mel_test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    melspec_train_dataset,\n",
    "    shuffle=True,\n",
    "    num_workers=8,\n",
    "    batch_size=8\n",
    ")\n",
    "validation_dataloader = torch.utils.data.DataLoader(\n",
    "    melspec_valid_dataset,\n",
    "    batch_size=8\n",
    ")\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    mel_test_dataset,\n",
    "    batch_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WavLM Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavlm_train_dataset = EmoUERJFeatureDataset(\n",
    "    data_path='emoUERJ_wavlm_features',\n",
    "    actor_ids=[1, 2]\n",
    ")\n",
    "wavlm_valid_dataset = EmoUERJFeatureDataset(\n",
    "    data_path='emoUERJ_wavlm_features',\n",
    "    actor_ids=[3]\n",
    ")\n",
    "wavlm_test_dataset = EmoUERJFeatureDataset(\n",
    "    data_path='emoUERJ_wavlm_features',\n",
    "    actor_ids=[4]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavlm_train_dataloader = torch.utils.data.DataLoader(\n",
    "    wavlm_train_dataset,\n",
    "    shuffle=True,\n",
    "    # num_workers=8,\n",
    "    batch_size=8\n",
    ")\n",
    "wavlm_validation_dataloader = torch.utils.data.DataLoader(\n",
    "    wavlm_valid_dataset,\n",
    "    batch_size=8\n",
    ")\n",
    "wavlm_test_dataloader = torch.utils.data.DataLoader(\n",
    "    wavlm_test_dataset,\n",
    "    batch_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hubert Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "hubert_train_dataset = EmoUERJFeatureDataset(\n",
    "    data_path='emoUERJ_hubert_features',\n",
    "    actor_ids=[1, 2]\n",
    ")\n",
    "hubert_valid_dataset = EmoUERJFeatureDataset(\n",
    "    data_path='emoUERJ_hubert_features',\n",
    "    actor_ids=[3]\n",
    ")\n",
    "hubert_test_dataset = EmoUERJFeatureDataset(\n",
    "    data_path='emoUERJ_hubert_features',\n",
    "    actor_ids=[4]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hubert_train_dataloader = torch.utils.data.DataLoader(\n",
    "    hubert_train_dataset,\n",
    "    shuffle=True,\n",
    "    # num_workers=8,\n",
    "    batch_size=8\n",
    ")\n",
    "hubert_validation_dataloader = torch.utils.data.DataLoader(\n",
    "    hubert_valid_dataset,\n",
    "    batch_size=8\n",
    ")\n",
    "hubert_test_dataloader = torch.utils.data.DataLoader(\n",
    "    hubert_test_dataset,\n",
    "    batch_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_config = ProjectConfiguration(\n",
    "    total_limit=5,  # Keep only the latest 10 checkpoints\n",
    "    automatic_checkpoint_naming=True  # Enable automatic naming\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class TrainingConfig:\n",
    "\n",
    "    def __init__(self, model_name):\n",
    "        self.model_name = model_name\n",
    "\n",
    "        self.output_dir = f\"models/{self.model_name}\"\n",
    "        self.hub_model_id = f\"paulovsantanas/{self.model_name}\"\n",
    "\n",
    "    train_batch_size = 64\n",
    "    # eval_batch_size = 16\n",
    "    num_epochs = 50\n",
    "    gradient_accumulation_steps = 1\n",
    "    learning_rate = 1e-4\n",
    "    lr_warmup_steps = 10\n",
    "    save_model_steps = 10\n",
    "    mixed_precision = \"fp16\"\n",
    "    # output_dir = f\"models/{self.model_name}\"  # the model name locally and on the HF Hub\n",
    "    # push_to_hub = False  # whether to upload the saved model to the HF Hub\n",
    "    # hub_model_id = f\"paulovsantanas/{self.model_name}\"  # the name of the repository to create on the HF Hub\n",
    "    # hub_private_repo = True\n",
    "    overwrite_output_dir = True  # overwrite the old model when re-running the notebook\n",
    "    seed = 0\n",
    "    # max_train_samples = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "\n",
    "def train_accelerate(\n",
    "    model,\n",
    "    optimizer,\n",
    "    lr_scheduler,\n",
    "    criterium,\n",
    "    train_dataloader,\n",
    "    validation_dataloader,\n",
    "    config: TrainingConfig,\n",
    "    project_config: ProjectConfiguration,\n",
    "):\n",
    "    accelerator = Accelerator(\n",
    "        mixed_precision=config.mixed_precision,\n",
    "        gradient_accumulation_steps=config.gradient_accumulation_steps,\n",
    "        log_with=\"wandb\",\n",
    "        project_dir=os.path.join(config.output_dir),\n",
    "        project_config=project_config,\n",
    "    )\n",
    "    if accelerator.is_main_process:\n",
    "        if config.output_dir is not None:\n",
    "            os.makedirs(config.output_dir, exist_ok=True)\n",
    "        accelerator.init_trackers(\n",
    "            \"pav-ser\",\n",
    "            init_kwargs={\"wandb\": {\"name\": f\"{config.model_name}_{uuid.uuid4()}\"}},\n",
    "        )\n",
    "\n",
    "    model, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(\n",
    "        model, optimizer, train_dataloader, lr_scheduler\n",
    "    )\n",
    "\n",
    "    progress_bar = tqdm(\n",
    "        total=config.num_epochs, disable=not accelerator.is_local_main_process\n",
    "    )\n",
    "    progress_bar.set_description(f\"Epoch\")\n",
    "\n",
    "    global_step = 0\n",
    "\n",
    "    # Train\n",
    "    for epoch in range(config.num_epochs):\n",
    "        epoch_acc = []\n",
    "        epoch_loss = []\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            with accelerator.accumulate(model):\n",
    "                model.train()\n",
    "\n",
    "                audio = batch[0].to(DEVICE)\n",
    "                labels = batch[1].to(DEVICE)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(audio)\n",
    "\n",
    "                loss = criterium(outputs, labels)\n",
    "                accelerator.backward(loss)\n",
    "                accelerator.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "                optimizer.step()\n",
    "                lr_scheduler.step()\n",
    "\n",
    "                global_step += 1\n",
    "                logs = {}\n",
    "\n",
    "                # Evaluate\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    # Train metrics\n",
    "                    epoch_loss.append(loss.float().cpu().item())\n",
    "\n",
    "                    preds = torch.argmax(\n",
    "                        torch.nn.functional.softmax(outputs, dim=-1), dim=-1\n",
    "                    )\n",
    "                    epoch_acc.extend((preds == labels).float().cpu().numpy())\n",
    "\n",
    "                    epoch_avg_loss = sum(epoch_loss) / len(epoch_loss)\n",
    "                    epoch_avg_acc = sum(epoch_acc) / len(epoch_acc)\n",
    "\n",
    "                    logs = {\n",
    "                        \"Train Average Loss\": epoch_avg_loss,\n",
    "                        \"Train Average Accuracy\": epoch_avg_acc,\n",
    "                    }\n",
    "\n",
    "                    # Validation metrics\n",
    "                    if step == len(train_dataloader) - 1:\n",
    "                        validation_loss = []\n",
    "                        validation_acc = []\n",
    "                        for audio, labels in validation_dataloader:\n",
    "                            audio = audio.to(DEVICE)\n",
    "                            labels = labels.to(DEVICE)\n",
    "\n",
    "                            validation_outputs = model(audio)\n",
    "                            validation_loss.append(\n",
    "                                criterium(validation_outputs, labels)\n",
    "                                .float()\n",
    "                                .cpu()\n",
    "                                .item()\n",
    "                            )\n",
    "\n",
    "                            validation_preds = torch.argmax(\n",
    "                                torch.nn.functional.softmax(validation_outputs, dim=-1),\n",
    "                                dim=-1,\n",
    "                            )\n",
    "                            validation_acc.extend(\n",
    "                                (validation_preds == labels).float().cpu().numpy()\n",
    "                            )\n",
    "\n",
    "                        validation_avg_loss = sum(validation_loss) / len(\n",
    "                            validation_loss\n",
    "                        )\n",
    "                        validation_avg_acc = sum(validation_acc) / len(validation_acc)\n",
    "\n",
    "                        logs[\"Validation Average Loss\"] = validation_avg_loss\n",
    "                        logs[\"Validation Average Accuracy\"] = validation_avg_acc\n",
    "\n",
    "                logs[\"lr\"] = lr_scheduler.get_last_lr()[0]\n",
    "                logs[\"step\"] = global_step + 1\n",
    "                # logs = {\"loss\": loss.detach().item(), \"lr\": lr_scheduler.get_last_lr()[0], \"step\": global_step+1}\n",
    "                accelerator.log(logs, step=global_step)\n",
    "                # progress_bar.set_postfix(**logs)\n",
    "\n",
    "            if accelerator.is_main_process:\n",
    "                if (global_step + 1) % config.save_model_steps == 0 or global_step == (\n",
    "                    config.num_epochs * len(train_dataloader)\n",
    "                ) - 1:\n",
    "                    accelerator.save_state(config.output_dir)\n",
    "        progress_bar.update(1)\n",
    "    accelerator.end_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "def test(model, test_dataloader):\n",
    "    model.eval()\n",
    "\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    for x, y in tqdm(test_dataloader):\n",
    "        x = x.to(DEVICE)\n",
    "        y = y.cpu()\n",
    "\n",
    "        # y_true.append(int(y))\n",
    "        y_true.extend(y.int())\n",
    "\n",
    "        out = model(x)\n",
    "\n",
    "        pred = torch.argmax(\n",
    "            torch.nn.functional.softmax(out, dim=-1),\n",
    "            dim=-1\n",
    "        ).cpu()\n",
    "\n",
    "        # y_pred.append(int(pred))\n",
    "        y_pred.extend(pred.int())\n",
    "\n",
    "    print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN 2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2DBlock(nn.Module):\n",
    "    def __init__(self,\n",
    "                 config,\n",
    "                 in_channels=1,\n",
    "                 out_channels=32,\n",
    "                 kernel_size=(3, 3)):\n",
    "        # Inicializa a classe Conv2DBlock que herda de nn.Module\n",
    "        super(Conv2DBlock, self).__init__()\n",
    "        # Atributos da classe\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        # Define a operação de convolução\n",
    "        self.conv = nn.Conv2d(\n",
    "            self.in_channels,\n",
    "            self.out_channels,\n",
    "            stride=config[\"stride\"],\n",
    "            kernel_size=kernel_size\n",
    "        )\n",
    "\n",
    "        # Define o tipo de normalização que será utilizado\n",
    "        if config[\"norm\"] == \"group_normalization\":\n",
    "            self.norm = nn.GroupNorm(self.in_channels, self.out_channels)\n",
    "        elif config[\"norm\"] == \"batch_normalization\":\n",
    "            self.norm = nn.BatchNorm2d(self.out_channels)\n",
    "        elif config[\"norm\"] == \"instance_normalization\":\n",
    "            self.norm = nn.InstanceNorm2d(self.out_channels)\n",
    "        else:\n",
    "            self.norm = None\n",
    "\n",
    "        # Define a função de ativação que será utilizada\n",
    "        if config[\"activation\"] == \"relu\":\n",
    "            self.activation = nn.ReLU()\n",
    "        elif config[\"activation\"] == \"mish\":\n",
    "            self.activation = nn.Mish()\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported activation: {config.activation}\")\n",
    "\n",
    "        # Define o tipo de pooling que será utilizado\n",
    "        if config[\"pooling\"]:\n",
    "            self.pooling = nn.MaxPool2d(tuple(config[\"pooling_ks\"]))\n",
    "        else:\n",
    "            self.pooling = None\n",
    "\n",
    "        # Define a técnica de regularização que será utilizada\n",
    "        if config[\"dropout\"] > 0:\n",
    "            self.dropout = nn.Dropout2d(config[\"dropout\"])\n",
    "        else:\n",
    "            self.dropout = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, 1, T, num_feature]\n",
    "        x = self.conv(x)\n",
    "        # x: [B, n_filters, T, num_feature]\n",
    "        if self.norm is not None:\n",
    "            x = self.norm(x)\n",
    "        x = self.activation(x)\n",
    "        if self.pooling:\n",
    "            x = self.pooling(x)\n",
    "        if self.dropout:\n",
    "            x = self.dropout(x)\n",
    "        # x: [B, n_filters, T, num_feature]\n",
    "        return x\n",
    "    \n",
    "class SERCNN2D(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(SERCNN2D, self).__init__()\n",
    "\n",
    "        # Setup convolutional blocks\n",
    "        conv_block_kernels = config[\"conv_block_kernels\"] # Lista de tamanhos de kernel para as camadas convolucionais\n",
    "        conv_block_kernels.reverse() # Inverte a lista para começar com o menor kernel\n",
    "        # Cria a primeira camada convolucional\n",
    "        init_layer = Conv2DBlock(config[\"conv_block\"],\n",
    "                                  out_channels=config[\"conv_block_dims\"][0],\n",
    "                                  kernel_size=tuple(conv_block_kernels.pop()))\n",
    "        conv_blocks = [init_layer] # Lista para armazenar as camadas convolucionais\n",
    "        inc = config[\"conv_block_dims\"][0] # Número de canais de entrada para a próxima camada\n",
    "        # Cria as outras camadas convolucionais\n",
    "        for dim in config[\"conv_block_dims\"][1:]:\n",
    "            kernel_size = tuple(conv_block_kernels.pop())\n",
    "            conv_blocks.append(Conv2DBlock(config[\"conv_block\"],\n",
    "                                            kernel_size=kernel_size,\n",
    "                                            in_channels=inc,\n",
    "                                            out_channels=dim))\n",
    "            inc = dim\n",
    "        self.conv_blocks_module = nn.Sequential(*conv_blocks)\n",
    "\n",
    "        # Setup linear layers\n",
    "        _input = torch.zeros(torch.Size(ast.literal_eval(config[\"input_size\"]))).unsqueeze(0)\n",
    "\n",
    "        # Cria um tensor para determinar o tamanho de entrada da camada totalmente conectada 1\n",
    "        dummy_tensor = self.conv_blocks_module(_input)\n",
    "        fc1_in = 1\n",
    "        for s in dummy_tensor.size()[1:]:\n",
    "            fc1_in *= s\n",
    "\n",
    "        # Função para criar uma camada linear com as especificações dadas\n",
    "        def setup_linear_block(cfg, in_channels):\n",
    "            block = []\n",
    "\n",
    "            block = []\n",
    "            dim = cfg[\"dim\"]\n",
    "            block.append(nn.Linear(in_channels, dim))\n",
    "            if cfg[\"dropout\"] > 0:\n",
    "                block.append(nn.Dropout(cfg[\"dropout\"]))\n",
    "            if cfg[\"activation\"] == \"relu\":\n",
    "                block.append(nn.ReLU())\n",
    "            else:\n",
    "                raise ValueError(f'Unsupported activation: {cfg[\"activation\"]}')\n",
    "\n",
    "            return nn.Sequential(*block), dim\n",
    "\n",
    "        # Cria as camadas totalmente conectadas\n",
    "        self.fc1, fc2_in = setup_linear_block(config[\"fc1\"], fc1_in)\n",
    "        self.fc2, out_in = setup_linear_block(config[\"fc2\"], fc2_in)\n",
    "\n",
    "        # Camada de projeção para a saída\n",
    "        self.proj = nn.Linear(out_in, config[\"num_labels\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Passa o sinal de entrada pelas camadas convolucionais\n",
    "        x = self.conv_blocks_module(x)\n",
    "\n",
    "        # Transforma o tensor resultante em um vetor\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # Passa o vetor pela camada totalmente conectada 1\n",
    "        x = self.fc1(x)\n",
    "        # Passa o vetor pela camada totalmente conectada 2\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        # Passa o vetor pela camada de projeção para obter a saída\n",
    "        return self.proj(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "        \"input_size\": '(1, 80, 219)',\n",
    "        \"conv_block\": {\n",
    "            \"dropout\": 0.25,\n",
    "            \"norm\": \"batch_normalization\",\n",
    "            \"activation\": \"mish\",\n",
    "            \"pooling\": True,\n",
    "            \"pooling_ks\": [2, 2],\n",
    "            \"stride\": 1\n",
    "        },\n",
    "        \"fc1\": {\n",
    "            \"dim\": 512,\n",
    "            \"activation\": \"relu\",\n",
    "            \"dropout\": 0.25\n",
    "        },\n",
    "        \"fc2\": {\n",
    "            \"dim\": 256,\n",
    "            \"activation\": \"relu\",\n",
    "            \"dropout\": 0.25\n",
    "        },\n",
    "        \"conv_block_kernels\": [[3, 3], [3, 3], [3, 3]],\n",
    "        \"conv_block_dims\": [64, 32, 16],\n",
    "        \"num_labels\": 4\n",
    "}\n",
    "\n",
    "cnn2d_training_config = TrainingConfig('pav-cnn2d-ser')\n",
    "cnn2d_training_config.num_epochs = 50\n",
    "cnn2d_training_config.train_batch_size = 8\n",
    "cnn2d_training_config.save_model_steps = 50\n",
    "\n",
    "cnn2d_model = SERCNN2D(config)\n",
    "cnn2d_optimizer = torch.optim.AdamW(cnn2d_model.parameters(), lr=cnn2d_training_config.learning_rate)\n",
    "cnn2d_lr_scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer=cnn2d_optimizer,\n",
    "    num_warmup_steps=cnn2d_training_config.lr_warmup_steps,\n",
    "    num_training_steps=cnn2d_training_config.num_epochs*len(train_dataloader),\n",
    ")\n",
    "cnn2d_criterium = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/e/Universidade Federal de Goiás/Mestrado/pav/projeto_final/sentiment-analysis/wandb/run-20240708_175526-3e6sfxwe</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/paulovsantanasteam/pav-ser/runs/3e6sfxwe' target=\"_blank\">pav-cnn2d-ser_5900138c-df39-407f-af04-e06b6b078393</a></strong> to <a href='https://wandb.ai/paulovsantanasteam/pav-ser' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/paulovsantanasteam/pav-ser' target=\"_blank\">https://wandb.ai/paulovsantanasteam/pav-ser</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/paulovsantanasteam/pav-ser/runs/3e6sfxwe' target=\"_blank\">https://wandb.ai/paulovsantanasteam/pav-ser/runs/3e6sfxwe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afd012a0850944a59bbe039d2c41182d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6f854747514454690cf33d3c3fdc310",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train Average Accuracy</td><td>▁▄▄▅▅▅▆▇▅▆▆▆▇▆▇▇▇▆▇▇▇▇▇▆▇▇█▇▇█▇▇▇▇▇█▇█▇▇</td></tr><tr><td>Train Average Loss</td><td>█▇▇▆▅▄▄▃▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▂▂▃▂▂▂▃▂▂▁▂▂</td></tr><tr><td>Validation Average Accuracy</td><td>▁▃▄▆█▄▂▆▅▆▄▇▄▄▄▅▄▂▆▆▆▂▆▅▆▄▅▅▆▄▃▄▄▃▄▅▃▄▆▄</td></tr><tr><td>Validation Average Loss</td><td>▇▅▄▃▁▂▃▂▃▂▄▂▃▃▃▃▄▅▂▂▃▅▄▄▄▆▆▄▄▆▆▆▅▅▆▃▇█▅▆</td></tr><tr><td>lr</td><td>███████▇▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train Average Accuracy</td><td>0.8973</td></tr><tr><td>Train Average Loss</td><td>0.28788</td></tr><tr><td>Validation Average Accuracy</td><td>0.57471</td></tr><tr><td>Validation Average Loss</td><td>1.2433</td></tr><tr><td>lr</td><td>0.0</td></tr><tr><td>step</td><td>1201</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">pav-cnn2d-ser_5900138c-df39-407f-af04-e06b6b078393</strong> at: <a href='https://wandb.ai/paulovsantanasteam/pav-ser/runs/3e6sfxwe' target=\"_blank\">https://wandb.ai/paulovsantanasteam/pav-ser/runs/3e6sfxwe</a><br/> View project at: <a href='https://wandb.ai/paulovsantanasteam/pav-ser' target=\"_blank\">https://wandb.ai/paulovsantanasteam/pav-ser</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240708_175526-3e6sfxwe/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_accelerate(\n",
    "    cnn2d_model,\n",
    "    cnn2d_optimizer,\n",
    "    cnn2d_lr_scheduler,\n",
    "    cnn2d_criterium,\n",
    "    train_dataloader,\n",
    "    validation_dataloader,\n",
    "    cnn2d_training_config,\n",
    "    project_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50a2e32805e5482fba9e4b27d6415c43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.32      0.41        22\n",
      "           1       0.62      0.69      0.65        26\n",
      "           2       0.79      0.84      0.82        37\n",
      "           3       0.56      0.70      0.62        20\n",
      "\n",
      "    accuracy                           0.67       105\n",
      "   macro avg       0.64      0.64      0.63       105\n",
      "weighted avg       0.66      0.67      0.65       105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(cnn2d_model, test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, num_layers, input_dim, output_dim, hidden_size=200) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.input_proj = self.__create_linear_block(input_dim, hidden_size)\n",
    "\n",
    "        if num_layers:\n",
    "            self.hidden_layers = []\n",
    "            for i in range(num_layers):\n",
    "                self.hidden_layers.append(\n",
    "                    self.__create_linear_block(hidden_size, hidden_size)\n",
    "                )\n",
    "            self.hidden_layers = nn.Sequential(*self.hidden_layers)\n",
    "        self.output_proj = nn.Linear(hidden_size, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.input_proj(x)\n",
    "        x = self.hidden_layers(x)\n",
    "        y = self.output_proj(x)\n",
    "\n",
    "        return y\n",
    "    \n",
    "    def __create_linear_block(self, input_dim, output_dim):\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(input_dim, output_dim),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.ReLU()\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WavLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = wavlm_train_dataloader.dataset[0][0].size()\n",
    "\n",
    "mlp_training_config = TrainingConfig('pav-mlp-ser-wavlm')\n",
    "mlp_training_config.num_epochs = 200\n",
    "mlp_training_config.lr_warmup_steps = 400\n",
    "mlp_training_config.train_batch_size = 8\n",
    "mlp_training_config.save_model_steps = 50\n",
    "mlp_training_config.learning_rate = 5e-5\n",
    "\n",
    "mlp_model = MLP(2, dimensions[1] * dimensions[2] , 4, 200)\n",
    "mlp_model.to(DEVICE)\n",
    "mlp_optimizer = torch.optim.AdamW(mlp_model.parameters(), lr=mlp_training_config.learning_rate)\n",
    "mlp_lr_scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer=mlp_optimizer,\n",
    "    num_warmup_steps=mlp_training_config.lr_warmup_steps,\n",
    "    num_training_steps=mlp_training_config.num_epochs*len(wavlm_train_dataloader),\n",
    ")\n",
    "mlp_criterium = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/e/Universidade Federal de Goiás/Mestrado/pav/projeto_final/sentiment-analysis/wandb/run-20240709_015516-r8rrcbjp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/paulovsantanasteam/pav-ser/runs/r8rrcbjp' target=\"_blank\">pav-mlp-ser-wavlm_3c12f36b-ff62-4ef1-a2b7-37bc596dd444</a></strong> to <a href='https://wandb.ai/paulovsantanasteam/pav-ser' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/paulovsantanasteam/pav-ser' target=\"_blank\">https://wandb.ai/paulovsantanasteam/pav-ser</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/paulovsantanasteam/pav-ser/runs/r8rrcbjp' target=\"_blank\">https://wandb.ai/paulovsantanasteam/pav-ser/runs/r8rrcbjp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00efcff15c104ea8a00fd226f49acd7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "708b4888305f49e3bf43138eb6e77ac6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train Average Accuracy</td><td>▁▄▆▅▅▇▇▇▇█▆█▇▇▇█▇▇▇█▇██▇███▇███▇████▇█▇█</td></tr><tr><td>Train Average Loss</td><td>▇▇▆█▄▃▃▂▂▂▃▂▂▂▁▁▄▂▁▁▇▁▂▂▁▆▁▁▁▁▁█▁▁▁▁▁▁▁▁</td></tr><tr><td>Validation Average Accuracy</td><td>▁▅▃▆▄▇▆▇▇▇▇▇▇▅▆██▇█▇▇▇▇▇▇▄▇▇▇▆▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>Validation Average Loss</td><td>▁▁▂▁▁▁▁▂▁▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▂█▃▂▃▂▃▂▂▂▂▂▂▂▂▂</td></tr><tr><td>lr</td><td>▂▃▅███████▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train Average Accuracy</td><td>0.97838</td></tr><tr><td>Train Average Loss</td><td>0.09577</td></tr><tr><td>Validation Average Accuracy</td><td>0.77011</td></tr><tr><td>Validation Average Loss</td><td>7.05009</td></tr><tr><td>lr</td><td>0.0</td></tr><tr><td>step</td><td>4801</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">pav-mlp-ser-wavlm_3c12f36b-ff62-4ef1-a2b7-37bc596dd444</strong> at: <a href='https://wandb.ai/paulovsantanasteam/pav-ser/runs/r8rrcbjp' target=\"_blank\">https://wandb.ai/paulovsantanasteam/pav-ser/runs/r8rrcbjp</a><br/> View project at: <a href='https://wandb.ai/paulovsantanasteam/pav-ser' target=\"_blank\">https://wandb.ai/paulovsantanasteam/pav-ser</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240709_015516-r8rrcbjp/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_accelerate(\n",
    "    mlp_model,\n",
    "    mlp_optimizer,\n",
    "    mlp_lr_scheduler,\n",
    "    mlp_criterium,\n",
    "    wavlm_train_dataloader,\n",
    "    wavlm_validation_dataloader,\n",
    "    mlp_training_config,\n",
    "    project_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f46f972b10614897b03d59bacf1e2d68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.45      0.49        22\n",
      "           1       0.76      0.73      0.75        26\n",
      "           2       0.74      0.46      0.57        37\n",
      "           3       0.37      0.70      0.48        20\n",
      "\n",
      "    accuracy                           0.57       105\n",
      "   macro avg       0.60      0.59      0.57       105\n",
      "weighted avg       0.63      0.57      0.58       105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(mlp_model, wavlm_test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HuBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = hubert_train_dataloader.dataset[0][0].size()\n",
    "\n",
    "mlp_training_config = TrainingConfig('pav-mlp-ser-hubert')\n",
    "mlp_training_config.num_epochs = 100\n",
    "mlp_training_config.lr_warmup_steps = 100\n",
    "mlp_training_config.train_batch_size = 8\n",
    "mlp_training_config.save_model_steps = 50\n",
    "mlp_training_config.learning_rate = 5e-5\n",
    "\n",
    "mlp_model = MLP(2, dimensions[1] * dimensions[2] , 4, 200)\n",
    "mlp_model.to(DEVICE)\n",
    "mlp_optimizer = torch.optim.AdamW(mlp_model.parameters(), lr=mlp_training_config.learning_rate)\n",
    "mlp_lr_scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer=mlp_optimizer,\n",
    "    num_warmup_steps=mlp_training_config.lr_warmup_steps,\n",
    "    num_training_steps=mlp_training_config.num_epochs*len(hubert_train_dataloader),\n",
    ")\n",
    "mlp_criterium = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/e/Universidade Federal de Goiás/Mestrado/pav/projeto_final/sentiment-analysis/wandb/run-20240709_023957-u1w8tjfw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/paulovsantanasteam/pav-ser/runs/u1w8tjfw' target=\"_blank\">pav-mlp-ser-hubert_4e2514b8-8c6b-4a80-acc8-48cb2dfea2b5</a></strong> to <a href='https://wandb.ai/paulovsantanasteam/pav-ser' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/paulovsantanasteam/pav-ser' target=\"_blank\">https://wandb.ai/paulovsantanasteam/pav-ser</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/paulovsantanasteam/pav-ser/runs/u1w8tjfw' target=\"_blank\">https://wandb.ai/paulovsantanasteam/pav-ser/runs/u1w8tjfw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8547cf9953bf47faa67b81976709a4c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n",
      "Deleting 1 checkpoints to make room for new checkpoint.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06b43012bb424ccdb875b49dab4894bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.013 MB uploaded\\r'), FloatProgress(value=0.1454467599200685, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train Average Accuracy</td><td>▂▃▁▃▁▄▃▂▅▄▄▄▄▄▃▄▅▄▅▄▅▅▄▄▅▆▅▆▇▆▇▆▇▇▇▇▇██▇</td></tr><tr><td>Train Average Loss</td><td>▄▄█▂▁▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Validation Average Accuracy</td><td>▁▄▆▄▃▄▃▂▅▃▃▃▃▃▄▄▄▄▄▄▄▄▃▄▄▆▆▆█████▇██████</td></tr><tr><td>Validation Average Loss</td><td>▄▅▄▄▂▄▁▁▃▁▁▁▁▁▁▁▁▂▂▁▂▃▃▄▂███▅▇█▇▇▇▆▆▆▆▆▆</td></tr><tr><td>lr</td><td>▃▅██████▇▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train Average Accuracy</td><td>0.84324</td></tr><tr><td>Train Average Loss</td><td>0.53195</td></tr><tr><td>Validation Average Accuracy</td><td>0.64368</td></tr><tr><td>Validation Average Loss</td><td>6.1324</td></tr><tr><td>lr</td><td>0.0</td></tr><tr><td>step</td><td>2401</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">pav-mlp-ser-hubert_4e2514b8-8c6b-4a80-acc8-48cb2dfea2b5</strong> at: <a href='https://wandb.ai/paulovsantanasteam/pav-ser/runs/u1w8tjfw' target=\"_blank\">https://wandb.ai/paulovsantanasteam/pav-ser/runs/u1w8tjfw</a><br/> View project at: <a href='https://wandb.ai/paulovsantanasteam/pav-ser' target=\"_blank\">https://wandb.ai/paulovsantanasteam/pav-ser</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240709_023957-u1w8tjfw/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_accelerate(\n",
    "    mlp_model,\n",
    "    mlp_optimizer,\n",
    "    mlp_lr_scheduler,\n",
    "    mlp_criterium,\n",
    "    hubert_train_dataloader,\n",
    "    hubert_validation_dataloader,\n",
    "    mlp_training_config,\n",
    "    project_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "909f511fb76949f0a233adf0d1478dce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.36      0.50        22\n",
      "           1       0.73      0.62      0.67        26\n",
      "           2       0.93      0.35      0.51        37\n",
      "           3       0.31      0.90      0.46        20\n",
      "\n",
      "    accuracy                           0.52       105\n",
      "   macro avg       0.69      0.56      0.53       105\n",
      "weighted avg       0.73      0.52      0.54       105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(mlp_model, hubert_test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing features WavLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavlm_dataset = EmoUERJDataset(\n",
    "    FileToFeature(ModelFeatureExtractor(wavlm))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41b4e550b34f4257a99016eb4ecf6455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/377 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "folder = 'emoUERJ_wavlm_features'\n",
    "os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "for x, y, filename in tqdm(wavlm_dataset):\n",
    "    torch.save(x, f\"{folder}/{filename}.pt\", _use_new_zipfile_serialization=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing features HuBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "hubert_dataset = EmoUERJDataset(\n",
    "    FileToFeature(ModelFeatureExtractor(hubert))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 349, 1280])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hubert_dataset[0][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98086612cadd4e9b96b30b129c423b33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/377 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "folder = 'emoUERJ_hubert_features'\n",
    "os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "for x, y, filename in tqdm(hubert_dataset):\n",
    "    torch.save(x, f\"{folder}/{filename}.pt\", _use_new_zipfile_serialization=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
